{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecast the next month(s) for each Team Member, both for individual clients and total hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pylab as plt\n",
    "from plotnine import ggplot, aes, geom_line\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from statsmodels.graphics import tsaplots\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import hts\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Read Data\n",
    "df = pd.read_csv('data/dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Data Types\n",
    "df['Data Type'] = df['Data Type'].astype('category')\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df['Client'] = df['Client'].astype('category')\n",
    "df['Responsible'] = df['Responsible'].astype('category')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "def get_column_description(data):\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'category':\n",
    "            print(f'{col} unique values: {len(data[col].unique())}\\n')\n",
    "        elif data[col].dtype == 'datetime64[ns]':\n",
    "            print(f'Min Date: {data[col].min()}')\n",
    "            print(f'Max Date: {data[col].max()}\\n')\n",
    "        else:\n",
    "            print(f'{col}:\\n{df[col].describe()}\\n')\n",
    "\n",
    "get_column_description(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Responsible', 'Client']).count().rename(columns={'Data Type': 'Count'}).sort_values(by='Count', ascending=False).Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Team member with all 13 months with one client\n",
    "example = df.loc[(df.Responsible == 'Team Member 12') & (df.Client == 'Client 18')].sort_values(by='Month')\n",
    "example.index = pd.DatetimeIndex(example.Month, freq=pd.DatetimeIndex(example.Month).inferred_freq)\n",
    "\n",
    "display(example)\n",
    "\n",
    "(\n",
    "    ggplot(example)\n",
    "    + aes(x='Month', y='Est Hrs')\n",
    "    + geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because there aren't a complete 13-month range for each team member, do some pre-processing filling in empty months with zero\n",
    "\n",
    "def fill_empty_dates(data):\n",
    "    unique_pairs = data[['Responsible', 'Client']].drop_duplicates().sort_values(by=['Responsible', 'Client'])\n",
    "    dates = pd.concat([pd.DataFrame({'Month':pd.date_range(datetime(2021, 1, 1), periods=13, freq='1M') - pd.offsets.MonthBegin(1)})]*len(unique_pairs), ignore_index=True)\n",
    "    resp_cli = pd.concat([unique_pairs]*13, ignore_index=True).sort_values(by=['Responsible', 'Client'])\n",
    "    out = pd.DataFrame({\n",
    "        'Month':dates.Month,\n",
    "        'Responsible':resp_cli.Responsible,\n",
    "        'Client':resp_cli.Client\n",
    "    }).sort_values(by=['Responsible', 'Client', 'Month']).reset_index(drop=True)\n",
    "\n",
    "    out = pd.merge(out, data.drop(columns='Data Type', axis=1), how='left', on=['Month', 'Responsible', 'Client'])\n",
    "    out.loc[out['Est Hrs'].isna(), 'Est Hrs'] = 0\n",
    "    return out\n",
    "\n",
    "df = fill_empty_dates(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical tests/EDA - whether data is stationary, granger-causality, distributions, visualizations\n",
    "\n",
    "# One of the challenges with this dataset is there is only one \"cycle\" of data (only one complete year). \n",
    "# You typically need at least two complete cycles of data in order to infer any seasonality. However,\n",
    "# we can still make an effort to ensure the data is stationary (not a trend in the data) prior to \n",
    "# using any forecast methods where stationary data is a constraint.\n",
    "\n",
    "\n",
    "# Make data stationary by using the `diff()` function\n",
    "example['res'] = example['Est Hrs'].diff()\n",
    "\n",
    "(\n",
    "    ggplot(example)\n",
    "    + aes(x='Month', y='res')\n",
    "    + geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_plt = tsaplots.plot_acf(example.res.dropna(), lags = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Baseline of Example - a quick example of the \"Score to beat\"\n",
    "\n",
    "mod = ARIMA(example.res, order=(0,1,0))\n",
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())\n",
    "\n",
    "example['y_hat'] = res.predict()\n",
    "example.loc[datetime(2021,2,1), 'y_hat'] = example['Est Hrs'].iloc[0]\n",
    "example['y_hat'] = example['y_hat'].cumsum()\n",
    "(\n",
    "    ggplot(example[['Month', 'Est Hrs', 'y_hat']].melt(id_vars='Month'))\n",
    "    + aes(x='Month', y='value', color='variable')\n",
    "    + geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = ARIMA(example.res, order=(1,1,0))\n",
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())\n",
    "\n",
    "example['y_hat'] = res.predict()\n",
    "example.loc[datetime(2021,2,1), 'y_hat'] = example['Est Hrs'].iloc[0]\n",
    "example['y_hat'] = example['y_hat'].cumsum()\n",
    "(\n",
    "    ggplot(example[['Month', 'Est Hrs', 'y_hat']].melt(id_vars='Month'))\n",
    "    + aes(x='Month', y='value', color='variable')\n",
    "    + geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all data stationary\n",
    "df['res'] = df.groupby(['Responsible', 'Client'])['Est Hrs'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Baseline (Random Walk)\n",
    "\n",
    "def get_pred(data, pred, col):\n",
    "    data = data.reset_index(drop=True)\n",
    "    pred[1] = data.iloc[0]['Est Hrs']\n",
    "    data[col] = pred.cumsum().values\n",
    "    return data\n",
    "\n",
    "def naive_baseline(data):\n",
    "    data.index = pd.DatetimeIndex(data.Month, freq=pd.DatetimeIndex(data.Month).inferred_freq)\n",
    "    mod = ARIMA(data.res, order=(0,1,0), freq='MS')\n",
    "    data = get_pred(data, mod.fit().predict(), 'baseline')\n",
    "    return data\n",
    "\n",
    "#nb = df.groupby(['Responsible', 'Client'], as_index=False, observed=True).apply(func=naive_baseline).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heirarchal - Each client is a part of the whole for each Team Member; Each Team member is part of the overall Team\n",
    "\n",
    "def get_hierarchy(data, lvl1, lvl2):\n",
    "    new_ = f'{lvl1}_{lvl2}'\n",
    "    data[new_] = data.apply(lambda x: f'{x[lvl1]}_{x[lvl2]}', axis=1)\n",
    "    l1s = data[lvl1].unique()\n",
    "    l2s = data[new_].unique()\n",
    "    total = {'total': list(l1s)}\n",
    "    l1 = {k: [v for v in l2s if k == v.split('_')[0]] for k in l1s}\n",
    "    hier = {**total, **l1}\n",
    "    return hier, new_\n",
    "\n",
    "def get_hierarchal(data, lvl1, lvl2, date_col='Month', val='Est Hrs'):\n",
    "    hier, new_ = get_hierarchy(data, lvl1, lvl2)\n",
    "    hd = data.pivot(index=date_col, columns=new_, values=val)\\\n",
    "        .join(\n",
    "            data.groupby([date_col, lvl1], as_index=False, observed=True)\\\n",
    "                .agg({val : lambda x: data.loc[x.index][val].sum()})\\\n",
    "                    .pivot(index=date_col, columns=lvl1, values=val)\n",
    "            )\\\n",
    "                .join(\n",
    "                    data.groupby(date_col, observed=True)\\\n",
    "                        .agg({val : lambda x: data.loc[x.index][val].sum()})\\\n",
    "                            .rename(columns={val:'total'})\n",
    "                    )\n",
    "    return hier, hd\n",
    "\n",
    "hierarchy, hierarchy_df = get_hierarchal(df, 'Responsible', 'Client')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hier_arima(hdf, col, order=(1,1,0)):\n",
    "    mod = ARIMA(hdf[col].diff(), order=order, freq='MS')\n",
    "    mod = mod.fit()\n",
    "    #return mod.predict()\n",
    "    return mod\n",
    "\n",
    "    #example['y_hat'] = res.predict()\n",
    "    #example.loc[datetime(2021,2,1), 'y_hat'] = example['Est Hrs'].iloc[0]\n",
    "    #example['y_hat'] = example['y_hat'].cumsum()\n",
    "mod = hier_arima(hierarchy_df, 'total')\n",
    "mod.fitted_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw = hts.HTSRegressor(model='holt_winters', revision_method='OLS', n_jobs=1)\n",
    "hw = hw.fit(hierarchy_df, nodes=hierarchy)\n",
    "hw_pred = reg.predict(steps_ahead=1)\n",
    "\n",
    "auto_arima = hts.HTSRegressor(model='auto_arima', revision_method='OLS', n_jobs=1)\n",
    "auto_arima = auto_arima.fit(hierarchy_df, nodes=hierarchy)\n",
    "auto_arima_pred = auto_arima.predict(steps_ahead=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96f4c81d9610671b2e53233b12db74d2213c7a070e8be982936c6ca01f4a5ce6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
